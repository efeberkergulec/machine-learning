{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMPE 442: Machine Learning\n",
    "# Assignment: 2\n",
    "# Question: 1\n",
    "# Author: Efe Berk ERGULEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from sklearn.metrics import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions that I will use during this question'''\n",
    "# Loads CSV file\n",
    "def load_CSV_file(file):\n",
    "    with open(file) as csv_file:\n",
    "        csv_array = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        data = []\n",
    "        for row in csv_array:\n",
    "            data.append([])\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                for i in range(len(row)):\n",
    "                    data[line_count - 1].append(row[i])\n",
    "                line_count += 1\n",
    "    return data;\n",
    "\n",
    "# Splits dataset into training and test data\n",
    "def split_dataset(dataset):\n",
    "    s, ve, vi = np.array(dataset[0:50]), np.array(dataset[50:100]), np.array(dataset[100:150])\n",
    "    a = 49\n",
    "    s_tr = []\n",
    "    for i in range(40):\n",
    "        s_tr.append([])\n",
    "        k = random.randint(0,a)\n",
    "        for j in range(5):\n",
    "            s_tr[i].append(s[k][j])\n",
    "        a -= 1\n",
    "        np.delete(s, k)\n",
    "    s_te = []\n",
    "    for i in range(10):\n",
    "        s_te.append([])\n",
    "        for j in range(5):\n",
    "            s_te[i].append(s[i][j])\n",
    "    a = 49\n",
    "    ve_tr = []\n",
    "    for i in range(40):\n",
    "        ve_tr.append([])\n",
    "        k = random.randint(0,a)\n",
    "        for j in range(5):\n",
    "            ve_tr[i].append(ve[k][j])\n",
    "        a -= 1\n",
    "        np.delete(s, k)\n",
    "    ve_te = []\n",
    "    for i in range(10):\n",
    "        ve_te.append([])\n",
    "        for j in range(5):\n",
    "            ve_te[i].append(ve[i][j])\n",
    "    a = 49\n",
    "    vi_tr = []\n",
    "    for i in range(40):\n",
    "        vi_tr.append([])\n",
    "        k = random.randint(0,a)\n",
    "        for j in range(5):\n",
    "            vi_tr[i].append(vi[k][j])\n",
    "        a -= 1\n",
    "        np.delete(s, k)\n",
    "    vi_te = []\n",
    "    for i in range(10):\n",
    "        vi_te.append([])\n",
    "        for j in range(5):\n",
    "            vi_te[i].append(vi[i][j])\n",
    "    s_tr = np.array(s_tr)\n",
    "    s_te = np.array(s_te)\n",
    "    ve_tr = np.array(ve_tr)\n",
    "    ve_te = np.array(ve_te)\n",
    "    vi_tr = np.array(vi_tr)\n",
    "    vi_te = np.array(vi_te)\n",
    "    return s_tr, s_te, ve_tr, ve_te, vi_tr, vi_te\n",
    "\n",
    "# Calculates Prior Probabilities\n",
    "def pre_prob(y):\n",
    "    pre_probab = np.array([0,0,0])\n",
    "    for i in range(len(y)):\n",
    "        j = int(y[i])\n",
    "        if j == 0:\n",
    "            pre_probab[0] += 1\n",
    "        elif j == 1:\n",
    "            pre_probab[1] += 1\n",
    "        else:\n",
    "            pre_probab[2] += 1\n",
    "    pre_probab = np.around(np.true_divide(pre_probab, len(y)), decimals = 2)\n",
    "    return pre_probab\n",
    "\n",
    "# Computes mean\n",
    "def compute_mean(arr):\n",
    "    c = 0\n",
    "    for i in arr:\n",
    "        c += float(i)\n",
    "    return (c / len(arr))\n",
    "\n",
    "# Computes Variance\n",
    "def compute_variance(arr):\n",
    "    mn = 9999999.0\n",
    "    mx = 0.0\n",
    "    for i in arr:\n",
    "        if float(i) > mx:\n",
    "            mx = float(i)\n",
    "        elif float(i) < mn:\n",
    "            mn = float(i)\n",
    "    return mx - mn\n",
    "\n",
    "# Returns mean and variance of each class as an array\n",
    "def mean_var(setosa_train, versicolor_train, virginica_train):\n",
    "    # Setosa\n",
    "    mean = []\n",
    "    mean.append([])\n",
    "    variance = []\n",
    "    variance.append([])\n",
    "    setosa_sepallength_mean = np.around(compute_mean(setosa_train[:,0]), decimals = 2)\n",
    "    setosa_sepallength_variance = np.around(compute_variance(setosa_train[:,0]), decimals = 2)\n",
    "    setosa_sepalwidth_mean = np.around(compute_mean(setosa_train[:,1]), decimals = 2)\n",
    "    setosa_sepalwidth_variance = np.around(compute_variance(setosa_train[:,1]), decimals = 2)\n",
    "    setosa_petallength_mean = np.around(compute_mean(setosa_train[:,2]), decimals = 2)\n",
    "    setosa_petallength_variance = np.around(compute_variance(setosa_train[:,2]), decimals = 2)\n",
    "    setosa_petalwidth_mean = np.around(compute_mean(setosa_train[:,3]), decimals = 2)\n",
    "    setosa_petalwidth_variance = np.around(compute_variance(setosa_train[:,3]), decimals = 2)\n",
    "    \n",
    "    mean[0].append(setosa_sepallength_mean)\n",
    "    mean[0].append(setosa_sepalwidth_mean)\n",
    "    mean[0].append(setosa_petallength_mean)\n",
    "    mean[0].append(setosa_petalwidth_mean)\n",
    "    variance[0].append(setosa_sepallength_variance)\n",
    "    variance[0].append(setosa_sepalwidth_variance)\n",
    "    variance[0].append(setosa_petallength_variance)\n",
    "    variance[0].append(setosa_petalwidth_variance)\n",
    "    \n",
    "    # Versicolor\n",
    "    mean.append([])\n",
    "    variance.append([])\n",
    "    versicolor_sepallength_mean = np.around(compute_mean(versicolor_train[:,0]), decimals = 2)\n",
    "    versicolor_sepallength_variance = np.around(compute_variance(versicolor_train[:,0]), decimals = 2)\n",
    "    versicolor_sepalwidth_mean = np.around(compute_mean(versicolor_train[:,1]), decimals = 2)\n",
    "    versicolor_sepalwidth_variance = np.around(compute_variance(versicolor_train[:,1]), decimals = 2)\n",
    "    versicolor_petallength_mean = np.around(compute_mean(versicolor_train[:,2]), decimals = 2)\n",
    "    versicolor_petallength_variance = np.around(compute_variance(versicolor_train[:,2]), decimals = 2)\n",
    "    versicolor_petalwidth_mean = np.around(compute_mean(versicolor_train[:,3]), decimals = 2)\n",
    "    versicolor_petalwidth_variance = np.around(compute_variance(versicolor_train[:,3]), decimals = 2)\n",
    "    \n",
    "    mean[1].append(versicolor_sepallength_mean)\n",
    "    mean[1].append(versicolor_sepalwidth_mean)\n",
    "    mean[1].append(versicolor_petallength_mean)\n",
    "    mean[1].append(versicolor_petalwidth_mean)\n",
    "    variance[1].append(versicolor_sepallength_variance)\n",
    "    variance[1].append(versicolor_sepalwidth_variance)\n",
    "    variance[1].append(versicolor_petallength_variance)\n",
    "    variance[1].append(versicolor_petalwidth_variance)\n",
    "\n",
    "    # Virginica\n",
    "    mean.append([])\n",
    "    variance.append([])\n",
    "    virginica_sepallength_mean = np.around(compute_mean(virginica_train[:,0]), decimals = 2)\n",
    "    virginica_sepallength_variance = np.around(compute_variance(virginica_train[:,0]), decimals = 2)\n",
    "    virginica_sepalwidth_mean = np.around(compute_mean(virginica_train[:,1]), decimals = 2)\n",
    "    virginica_sepalwidth_variance = np.around(compute_variance(virginica_train[:,1]), decimals = 2)\n",
    "    virginica_petallength_mean = np.around(compute_mean(virginica_train[:,2]), decimals = 2)\n",
    "    virginica_petallength_variance = np.around(compute_variance(virginica_train[:,2]), decimals = 2)\n",
    "    virginica_petalwidth_mean = np.around(compute_mean(virginica_train[:,3]), decimals = 2)\n",
    "    virginica_petalwidth_variance = np.around(compute_variance(virginica_train[:,3]), decimals = 2)\n",
    "    \n",
    "    mean[2].append(virginica_sepallength_mean)\n",
    "    mean[2].append(virginica_sepalwidth_mean)\n",
    "    mean[2].append(virginica_petallength_mean)\n",
    "    mean[2].append(virginica_petalwidth_mean)\n",
    "    variance[2].append(virginica_sepallength_variance)\n",
    "    variance[2].append(virginica_sepalwidth_variance)\n",
    "    variance[2].append(virginica_petallength_variance)\n",
    "    variance[2].append(virginica_petalwidth_variance)\n",
    "    \n",
    "    mean = np.array(mean)\n",
    "    variance = np.array(variance)\n",
    "    \n",
    "    return mean, variance\n",
    "\n",
    "# Returns posterior probability\n",
    "def prob_feature_class(m, v, x):\n",
    "    n_features = m.shape[1]\n",
    "    pfc = np.ones(3)\n",
    "    for i in range(0, 3):\n",
    "        product = 1\n",
    "        for j in range(0, n_features):\n",
    "            product = product * (1/np.sqrt(2*3.14*v[i][j])) * np.exp(-0.5\n",
    "                                 * pow((x[j] - m[i][j]),2)/v[i][j])\n",
    "        pfc[i] = product\n",
    "    return pfc\n",
    "\n",
    "def find_accuracy(test, prediction):\n",
    "    c = 0\n",
    "    for i in range(len(test)):\n",
    "        if test[i] == prediction[i]:\n",
    "            c += 1\n",
    "    return c / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset, splits training and test data for each class and keeps training and test data into arrays.\n",
    "dataset = load_CSV_file('iris.csv')\n",
    "setosa_train, setosa_test, versicolor_train, versicolor_test, virginica_train, virginica_test = split_dataset(dataset)\n",
    "train_data = np.concatenate((setosa_train, versicolor_train, virginica_train), axis = 0)\n",
    "test_data = np.concatenate((setosa_test, versicolor_test, virginica_test), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares training data, calculate mean, variance of all classes of all features\n",
    "X_train = np.array(train_data[:, [0,1,2,3]])\n",
    "y_train = np.array(train_data[:, 4])\n",
    "\n",
    "values = {0: \"Iris-setosa\", 1: \"Iris-versicolor\", 2: \"Iris-virginica\"}\n",
    "\n",
    "for i in range(0,y_train.shape[0]):\n",
    "    if y_train[i] == \"Iris-setosa\":\n",
    "        y_train[i] = int(0)\n",
    "    elif y_train[i] == \"Iris-versicolor\":\n",
    "        y_train[i] = int(1)\n",
    "    else:\n",
    "        y_train[i] = int(2)\n",
    "\n",
    "# x = np.array([7.7,3.8,6.7,2.2])    # I put it here additionally, so that you can look all values specificly\n",
    "X_test = np.array(test_data[:,[0,1,2,3]])   # This will be my data\n",
    "y_test = np.array(test_data[:, 4])\n",
    "\n",
    "pre_probab = pre_prob(y_train)\n",
    "m, v = mean_var(setosa_train, versicolor_train, virginica_train)\n",
    "predictions = []\n",
    "for x in X_test:\n",
    "    x = x.astype(float)\n",
    "    pfc = prob_feature_class(m, v, x)\n",
    "    pcf = np.ones(3)\n",
    "    total_prob = 0\n",
    "    for i in range(0, 3):\n",
    "        total_prob = total_prob + (pfc[i] * pre_probab[i])\n",
    "    for i in range(0, 3):\n",
    "        pcf[i] = (pfc[i] * pre_probab[i])/total_prob\n",
    "    prediction = values[int(pcf.argmax())] \n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = [[4.9  3.38 1.44 0.22]\n",
      " [5.94 2.82 4.29 1.33]\n",
      " [6.56 3.   5.54 1.98]]\n",
      "Variance = [[1.4 1.5 0.9 0.3]\n",
      " [1.9 1.2 1.4 0.8]\n",
      " [2.3 1.6 1.8 1. ]]\n",
      "Prior Probabilites = [0.33 0.33 0.33]\n",
      "Posterior Probabilities = [4.98452380e-12 1.06969714e-03 6.44826447e-03]\n",
      "Final Conditional Probabilities = [6.63015330e-10 1.42285529e-01 8.57714471e-01]\n",
      "Prediction = Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Final values after all calculations (for this one it prints out last element of test data)\n",
    "print(\"Mean = {}\".format(m))                              # Output given below (mean for 3 classes of all features)\n",
    "print(\"Variance = {}\".format(v))                          # Output given below (variance for 3 classes of features)\n",
    "print(\"Prior Probabilites = {}\".format(pre_probab))       # Output given below (prior probabilities)\n",
    "print(\"Posterior Probabilities = {}\".format(pfc))         # Output given below (posterior probabilities)\n",
    "print(\"Final Conditional Probabilities = {}\".format(pcf)) # Conditional Probability of the classes given test-data\n",
    "print(\"Prediction = {}\".format(prediction))               # Output given below(final prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.33%\n",
      "--------------------------------------------------------\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       0.83      1.00      0.91        10\n",
      " Iris-virginica       1.00      0.80      0.89        10\n",
      "\n",
      "    avg / total       0.94      0.93      0.93        30\n",
      "\n",
      "--------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  8]]\n"
     ]
    }
   ],
   "source": [
    "# Prints accuracy, classification report and confusion matrix, which you wanted us for the first question.\n",
    "print(\"Accuracy = {}%\".format(np.around(find_accuracy(y_test, predictions), decimals=4) * 100))\n",
    "print(56 * '-')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']))\n",
    "print(56 * '-')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions, ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
